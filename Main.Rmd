---
title: "Practical Machine Learning Course Project"
author: "Eduardo V. Kuri"
output: html_document
---

## Introduction

>We will predict, given some data retrieved from the training set, the type of exercise done, ranging from A (exactly according to specification), B (Throwing the elbows to the front), C (Lifting the dumbell only halfway), D (Lowering the dumbell only halfway), and E (Throwing the hips to the front).

## Retrieval of Data

> First off, we need to obtain our data and install the caret library. We will do that in the following code snippet:

```{r setup}

require(caret)


if(!exists("trainraw")){
  
  trainraw <- read.csv("~/UNAM 2020-24/DATSCI/MachineLearning/pml-training.csv")

}

if(!exists("testraw")){
  
  testraw <- read.csv("~/UNAM 2020-24/DATSCI/MachineLearning/pml-testing.csv")

}
```


>Now we proceed to do some exploratory analysis in order to obtain the approximate dimensions of the sets as well as the percentage of it devoted to training and testing.

```{r expana}

print(c(dim(testraw)[1], dim(trainraw)[1]))

per <- 100*dim(trainraw)[1]/(dim(testraw)[1]+dim(trainraw)[1])

print(paste("Percentage of training data:", round(per,4),"%", ", Percentage of testing data:", round(100-per,4),"%", ", Number of variables: ",dim(trainraw)[2]))

completecases <- complete.cases(trainraw)
print(length(completecases[completecases==TRUE]))


#Validation set


# Juntar modelos
```

> There seems to be a lot of information, and no guarantee that information will be of any use. We then clean the columns with NAs, in order to reduce the computational burden:

```{r cleanup0}
trainraw <- trainraw[, colSums(is.na(trainraw)) == 0]
testraw <- testraw[, colSums(is.na(testraw))==0]

```

>Now, we will eliminate all columns that can't be used (either because it is not numeric, or because of other reasons).

```{r cleanup}

classe <- trainraw$classe
trainRemove <- grepl("^X|timestamp|window", names(trainraw))
trainraw <- trainraw[, !trainRemove]
train <- trainraw[, sapply(trainraw, is.numeric)]
train$classe <- classe
testRemove <- grepl("^X|timestamp|window", names(testraw))
testraw <- testraw[, !testRemove]
test <- testraw[, sapply(testraw, is.numeric)]

set.seed(123345)

intrain <- createDataPartition(train$classe, p = 0.7, list=F)

validation <- train[-intrain,]
training <- train[intrain,]


```

## Training

>We will proceed to train the model using random forest and a 3-fold CV. This is done because of the discrete and categorical nature of the classe column (we will keep a cache file in order to speed up the process of knitting).

```{r training, cache=TRUE}
# instruct train to use 3-fold CV to select optimal tuning parameters
fitctrl <- trainControl(method="cv", number=3, verboseIter=F)
mod0 <- train(classe ~ ., data=training, method="rf", trControl = fitctrl)

mod0
```


## Prediction and Results

>Because of the already tough computational complexity, we will limit ourselves with the results from the training set. Now, we will predict the 20 cases from the test set.

```{r pred}

pred1 <- predict(mod0, test[,-length(names(test))])

print(pred1)



```

## Measurement of accuracy

>We shall now use the validation dataset to obtain the performance of our recently built model:

```{r performance}

pred2 <- predict(mod0, validation)
acc <- postResample(pred2, validation$classe)

```
>It is then given that the accuracy for this validation set is `r acc[1]*100`% and its Kappa is `r acc[2]*100`, which is surprising.

## Conclusions

>There seems to be a good model fit, that might predict well on small and medium data sets. 

## References

Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.
